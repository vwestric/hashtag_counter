{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Die Filterblasen der Anderen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import operator\n",
    "from eigenmodule import *\n",
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import cufflinks as cf\n",
    "import config\n",
    "import plotly.tools as tls\n",
    "tls.set_credentials_file(username=config.username, api_key=config.api_key)\n",
    "from IPython.display import HTML\n",
    "cf.set_config_file(offline=False, world_readable=True, theme='ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Anwendung\n",
    "\n",
    "Dies ist eine Anwendung zum Testen der Visualisierungskapazitäten der Python-Bibliothek 'plotly' basiernd auf Daten gewonnen mithilfe der Python-Bibliothek 'tweepy'.\n",
    "\n",
    "\n",
    "### 2. Daten\n",
    "\n",
    "#### 2.1 Beschreibung\n",
    "\n",
    "Grundlage der Daten sind ca. 4000 Twitter-Accounts, eingeteilt in vier Gruppen : Die erste Gruppe basiert auf einer Liste politisch konservativ bis extrem konservativ eingestellter Accounts zusammengetragen im Rahmen der 'Reconquista Internet'-Aktion Jan Böhmermanns. Aufgenommen in die Gruppe wurden die tausend Accounts mit den meisten Followern. Die drei anderen Gruppen basieren jeweils auf tausend Followern der Accounts von 'Spiegel Online', 'Taz - Die Tageszeitung', und der 'Identitäten Bewegung Österreich'.\n",
    "\n",
    "Über die Twitter-API wurden die Tweets dieser vier Gruppen im Zeitraum vom 19. August bis zum 6. September erfasst. Dieser Zeitraum wurde gewählt aufgrund der sich gleichzeitig in Chemnitz entfaltenden Ereignisse.\n",
    "\n",
    "#### 2.2 Problematik\n",
    "\n",
    "Vor allem in den Gruppen 2 bis 4 finden sich viele Nutzer, deren Accounts privat geschaltet sind und daher über die Twitter-API nicht verfügbar sind. Weiterhin sind manche Tweets durch Löschung nicht mehr verfügbar. Außerdem wurde nicht überprüft, ob hinter den Accounts Bots stehen oder nicht. Für die Darstellung ist dies allerdings zunächst vernachlässigbar. Weiterhin variiert das Tweet-Verhalten stark zwischen Nutzern, vor allem zwischen 'professionellen' und 'privaten'. Grundsätzlich ist in Frage zu stellen, wie repräsentativ Twitter als Datengrundlage ist.\n",
    "\n",
    "\n",
    "### 3. Inhaltliches Ziel\n",
    "\n",
    "Die Anwendung versucht, das Twitter-Verhalten der ersten Gruppe, der 'Böhermann-Liste', nachzuzeichnen. Zum Vergleich werden die anderen drei als Kontrollgruppen herangezogen.\n",
    "\n",
    "\n",
    "### 4. Methodik\n",
    "\n",
    "Visualisiert werden die von den jeweiligen Gruppen verwendeten Hashtags im Zeitraum vom 19. August bis zum 6. September. Die Darstellung wurde beschränkt auf die Hashtags, die an einem der Tage in diesem Zeitraum entweder der am häufigsten oder zweithäufigsten innerhalb dieser Gruppen verwendet wurden. Diese wurden der Anzahl nach auf einem Zeitstrahl als Liniendiagramm dargestellt.\n",
    "\n",
    "Aufgrund der außergewöhnlich hohen Zahl von Tweets unter dem Hashtag 'Chemnitz' wurden außerdem die Volltexte dieses Subsets von Tweets einbezogen. Disen wurden nach den am häufigsten verwendeten Wörtern und den am häufigsten verwendeten Adjektiv-Subjekt Kombinationen visualisiert.\n",
    "\n",
    "\n",
    "### 5. Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_dates = []\n",
    "hashtags_dict = {}\n",
    "\n",
    "with open(\"projektdaten/boehmermann_1000_hashtags_dated.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    file_name = str(file).strip(\"projektdaten/\")\n",
    "    file_name = file_name.strip(\"_hashtags_dated.txt\")\n",
    "    for line in file:\n",
    "        line_stripped = line.strip(\"\\ufeff\")\n",
    "        line_stripped = line_stripped.strip(\"\\n\")\n",
    "        line_splitted = line_stripped.split(\"|\")\n",
    "        line_1_stripped = line_splitted[1].strip(\"\\'\")\n",
    "        line_1_stripped = line_1_stripped.strip(\" \")\n",
    "        line_1_stripped = line_1_stripped.strip(\"[\")\n",
    "        line_1_stripped = line_1_stripped.strip(\"]\")\n",
    "        hashtags = line_1_stripped.split(\",\")\n",
    "\n",
    "        if line_splitted[0] not in hashtags_dict.keys():\n",
    "            hashtags_dict[line_splitted[0]] = hashtags\n",
    "        else:\n",
    "            hashtags_dict[line_splitted[0]].extend(hashtags)\n",
    "\n",
    "def removekey(d, key):\n",
    "    r = dict(d)\n",
    "    del r[key]\n",
    "    return r\n",
    "\n",
    "datelist = pd.date_range(pd.datetime.today()- timedelta(days=30), periods=30).tolist()\n",
    "datestrings = []\n",
    "for element in datelist:\n",
    "    datestrings.append(str(element.date()))\n",
    "\n",
    "\n",
    "hashtags_dict_new = {}\n",
    "\n",
    "for element in datestrings:\n",
    "    try:\n",
    "        hashtags_dict_new[element] = hashtags_dict[element]\n",
    "    except KeyError:\n",
    "        continue\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "hashtags_dict_counted = {}\n",
    "hashtags_dict_sorted = {}\n",
    "\n",
    "for key, value in hashtags_dict_new.items():\n",
    "    hashtags_dict_counted[key] = useful.count_occurrences(value)\n",
    "    \n",
    "    \n",
    "    \n",
    "key_list = []\n",
    "\n",
    "for key in hashtags_dict_counted.keys():\n",
    "    key_list.append(key)\n",
    "    \n",
    "key_list = sorted(key_list)\n",
    "\n",
    "\n",
    "\n",
    "hashtag_list = []\n",
    "\n",
    "for element in key_list:\n",
    "    hashtags_dict_sorted = sorted(hashtags_dict_counted[element].items(), key=operator.itemgetter(1), reverse=True)\n",
    "    if len(hashtags_dict_sorted) > 2:\n",
    "        for x in range(0, 2):\n",
    "            hashtag_list.append(hashtags_dict_sorted[x][0])\n",
    "    else:\n",
    "        for x in range(0, len(hashtags_dict_sorted)):\n",
    "            hashtag_list.append(hashtags_dict_sorted[x][0])\n",
    "        \n",
    "        \n",
    "hashtag_set = sorted(set(hashtag_list))\n",
    "\n",
    "\n",
    "\n",
    "hashtag_df = pd.DataFrame({\"Dates\":key_list})\n",
    "\n",
    "\n",
    "for hashtag in hashtag_set:\n",
    "    hashtag_value_list = []\n",
    "    for element in key_list:\n",
    "        try:\n",
    "            hashtag_value_list.append(hashtags_dict_counted[element][hashtag])\n",
    "        except KeyError:\n",
    "            hashtag_value_list.append(0)\n",
    "    hashtag_df[hashtag] = pd.Series(hashtag_value_list, index=hashtag_df.index)\n",
    "    \n",
    "hashtag_df_index = hashtag_df.set_index([\"Dates\"]).sort_index()\n",
    "\n",
    "#hashtag_df.to_csv(r'boehmermann_hashtag_df.txt', header=True, index=None, sep='|', mode='w', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Gruppe 1: 'Böhmermann-Liste'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~vwestric/119.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = go.Layout(\n",
    "    title='Am häufigsten verwendete Hashtags'\n",
    ")\n",
    "\n",
    "hashtag_df.iplot(x='Dates',kind='scatter', layout = layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~vwestric/121.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = []\n",
    "temp_values = []\n",
    "values = []\n",
    "\n",
    "phrase_dict = {}\n",
    "\n",
    "\n",
    "with open(\"bar_charts/boehmermann_chemnitz_tweets_phrase_count.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line_stripped = line.strip(\"\\n\")\n",
    "        line_splitted = line_stripped.split(\"|\")\n",
    "        temp_values.append(int(line_splitted[1]))\n",
    "        phrase_dict[line_splitted[0]] = int(line_splitted[1])\n",
    "        \n",
    "#((sum(temp_values)/len(temp_values)) * 2)      \n",
    "        \n",
    "for key, value in phrase_dict.items():\n",
    "    if value > ((sum(temp_values)/len(temp_values)) * 2):\n",
    "        phrases.append(key)\n",
    "        values.append(value)\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Am häufigsten verwendete Adjektiv-Subjektiv Kombinationen in #Chemnitz-Tweets'\n",
    ")        \n",
    "        \n",
    "data = [go.Bar(\n",
    "            x=phrases,\n",
    "            y=values\n",
    "    )]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~vwestric/123.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = []\n",
    "temp_values = []\n",
    "values = []\n",
    "\n",
    "phrase_dict = {}\n",
    "\n",
    "\n",
    "with open(\"bar_charts/boehmermann_chemnitz_tweets_word_count.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line_stripped = line.strip(\"\\n\")\n",
    "        line_splitted = line_stripped.split(\"|\")\n",
    "        temp_values.append(int(line_splitted[1]))\n",
    "        phrase_dict[line_splitted[0]] = int(line_splitted[1])\n",
    "        \n",
    "#((sum(temp_values)/len(temp_values)) * 2)      \n",
    "        \n",
    "for key, value in phrase_dict.items():\n",
    "    if value > ((sum(temp_values)/len(temp_values)) * 2):\n",
    "        phrases.append(key)\n",
    "        values.append(value)\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Am häufigsten verwendete Wörter in #Chemnitz-Tweets'\n",
    ")        \n",
    "        \n",
    "data = [go.Bar(\n",
    "            x=phrases,\n",
    "            y=values\n",
    "    )]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_dates = []\n",
    "hashtags_dict = {}\n",
    "\n",
    "with open(\"projektdaten/ib_liste_ueber_1000_hashtags_dated.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    file_name = str(file).strip(\"projektdaten/\")\n",
    "    file_name = file_name.strip(\"_hashtags_dated.txt\")\n",
    "    for line in file:\n",
    "        line_stripped = line.strip(\"\\ufeff\")\n",
    "        line_stripped = line_stripped.strip(\"\\n\")\n",
    "        line_splitted = line_stripped.split(\"|\")\n",
    "        line_1_stripped = line_splitted[1].strip(\"\\'\")\n",
    "        line_1_stripped = line_1_stripped.strip(\" \")\n",
    "        line_1_stripped = line_1_stripped.strip(\"[\")\n",
    "        line_1_stripped = line_1_stripped.strip(\"]\")\n",
    "        hashtags = line_1_stripped.split(\",\")\n",
    "\n",
    "        if line_splitted[0] not in hashtags_dict.keys():\n",
    "            hashtags_dict[line_splitted[0]] = hashtags\n",
    "        else:\n",
    "            hashtags_dict[line_splitted[0]].extend(hashtags)\n",
    "\n",
    "def removekey(d, key):\n",
    "    r = dict(d)\n",
    "    del r[key]\n",
    "    return r\n",
    "\n",
    "datelist = pd.date_range(pd.datetime.today()- timedelta(days=30), periods=30).tolist()\n",
    "datestrings = []\n",
    "for element in datelist:\n",
    "    datestrings.append(str(element.date()))\n",
    "\n",
    "\n",
    "hashtags_dict_new = {}\n",
    "\n",
    "for element in datestrings:\n",
    "    try:\n",
    "        hashtags_dict_new[element] = hashtags_dict[element]\n",
    "    except KeyError:\n",
    "        continue\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "hashtags_dict_counted = {}\n",
    "hashtags_dict_sorted = {}\n",
    "\n",
    "for key, value in hashtags_dict_new.items():\n",
    "    hashtags_dict_counted[key] = useful.count_occurrences(value)\n",
    "    \n",
    "    \n",
    "    \n",
    "key_list = []\n",
    "\n",
    "for key in hashtags_dict_counted.keys():\n",
    "    key_list.append(key)\n",
    "    \n",
    "key_list = sorted(key_list)\n",
    "\n",
    "\n",
    "\n",
    "hashtag_list = []\n",
    "\n",
    "for element in key_list:\n",
    "    hashtags_dict_sorted = sorted(hashtags_dict_counted[element].items(), key=operator.itemgetter(1), reverse=True)\n",
    "    if len(hashtags_dict_sorted) > 2:\n",
    "        for x in range(0, 2):\n",
    "            hashtag_list.append(hashtags_dict_sorted[x][0])\n",
    "    else:\n",
    "        for x in range(0, len(hashtags_dict_sorted)):\n",
    "            hashtag_list.append(hashtags_dict_sorted[x][0])\n",
    "        \n",
    "        \n",
    "hashtag_set = sorted(set(hashtag_list))\n",
    "\n",
    "\n",
    "\n",
    "hashtag_df = pd.DataFrame({\"Dates\":key_list})\n",
    "\n",
    "\n",
    "for hashtag in hashtag_set:\n",
    "    hashtag_value_list = []\n",
    "    for element in key_list:\n",
    "        try:\n",
    "            hashtag_value_list.append(hashtags_dict_counted[element][hashtag])\n",
    "        except KeyError:\n",
    "            hashtag_value_list.append(0)\n",
    "    hashtag_df[hashtag] = pd.Series(hashtag_value_list, index=hashtag_df.index)\n",
    "    \n",
    "    \n",
    "#hashtag_df.to_csv(r'ib_hashtag_df.txt', header=True, index=None, sep='|', mode='w', encoding=\"utf-8\")\n",
    "\n",
    "hashtag_df_index = hashtag_df.set_index([\"Dates\"]).sort_index()\n",
    "\n",
    "#hashtag_df.to_csv(r'boehmermann_hashtag_df.txt', header=True, index=None, sep='|', mode='w', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Gruppe 2: 'Identitäre Bewegung Österreich'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~vwestric/125.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = go.Layout(\n",
    "    title='Am häufigsten verwendete Hashtags'\n",
    ")\n",
    "\n",
    "hashtag_df.iplot(x='Dates',kind='scatter', layout = layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~vwestric/127.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = []\n",
    "temp_values = []\n",
    "values = []\n",
    "\n",
    "phrase_dict = {}\n",
    "\n",
    "\n",
    "with open(\"bar_charts/ib_chemnitz_tweets_phrase_count.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line_stripped = line.strip(\"\\n\")\n",
    "        line_splitted = line_stripped.split(\"|\")\n",
    "        temp_values.append(int(line_splitted[1]))\n",
    "        phrase_dict[line_splitted[0]] = int(line_splitted[1])\n",
    "        \n",
    "#((sum(temp_values)/len(temp_values)) * 2)      \n",
    "        \n",
    "for key, value in phrase_dict.items():\n",
    "    if value > ((sum(temp_values)/len(temp_values)) * 2):\n",
    "        phrases.append(key)\n",
    "        values.append(value)\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Am häufigsten verwendete Adjektiv-Subjektiv Kombinationen in #Chemnitz-Tweets'\n",
    ")        \n",
    "        \n",
    "data = [go.Bar(\n",
    "            x=phrases,\n",
    "            y=values\n",
    "    )]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~vwestric/129.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = []\n",
    "temp_values = []\n",
    "values = []\n",
    "\n",
    "phrase_dict = {}\n",
    "\n",
    "\n",
    "with open(\"bar_charts/ib_chemnitz_tweets_word_count.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line_stripped = line.strip(\"\\n\")\n",
    "        line_splitted = line_stripped.split(\"|\")\n",
    "        temp_values.append(int(line_splitted[1]))\n",
    "        phrase_dict[line_splitted[0]] = int(line_splitted[1])\n",
    "        \n",
    "#((sum(temp_values)/len(temp_values)) * 2)      \n",
    "        \n",
    "for key, value in phrase_dict.items():\n",
    "    if value > ((sum(temp_values)/len(temp_values)) * 2):\n",
    "        phrases.append(key)\n",
    "        values.append(value)\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Am häufigsten verwendete Wörter in #Chemnitz-Tweets'\n",
    ")        \n",
    "        \n",
    "data = [go.Bar(\n",
    "            x=phrases,\n",
    "            y=values\n",
    "    )]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_dates = []\n",
    "hashtags_dict = {}\n",
    "\n",
    "with open(\"projektdaten/taz_1000_hashtags_dated.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    file_name = str(file).strip(\"projektdaten/\")\n",
    "    file_name = file_name.strip(\"_hashtags_dated.txt\")\n",
    "    for line in file:\n",
    "        line_stripped = line.strip(\"\\ufeff\")\n",
    "        line_stripped = line_stripped.strip(\"\\n\")\n",
    "        line_splitted = line_stripped.split(\"|\")\n",
    "        line_1_stripped = line_splitted[1].strip(\"\\'\")\n",
    "        line_1_stripped = line_1_stripped.strip(\" \")\n",
    "        line_1_stripped = line_1_stripped.strip(\"[\")\n",
    "        line_1_stripped = line_1_stripped.strip(\"]\")\n",
    "        hashtags = line_1_stripped.split(\",\")\n",
    "\n",
    "        if line_splitted[0] not in hashtags_dict.keys():\n",
    "            hashtags_dict[line_splitted[0]] = hashtags\n",
    "        else:\n",
    "            hashtags_dict[line_splitted[0]].extend(hashtags)\n",
    "\n",
    "def removekey(d, key):\n",
    "    r = dict(d)\n",
    "    del r[key]\n",
    "    return r\n",
    "\n",
    "datelist = pd.date_range(pd.datetime.today()- timedelta(days=30), periods=30).tolist()\n",
    "datestrings = []\n",
    "for element in datelist:\n",
    "    datestrings.append(str(element.date()))\n",
    "\n",
    "\n",
    "hashtags_dict_new = {}\n",
    "\n",
    "for element in datestrings:\n",
    "    try:\n",
    "        hashtags_dict_new[element] = hashtags_dict[element]\n",
    "    except KeyError:\n",
    "        continue\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "hashtags_dict_counted = {}\n",
    "hashtags_dict_sorted = {}\n",
    "\n",
    "for key, value in hashtags_dict_new.items():\n",
    "    hashtags_dict_counted[key] = useful.count_occurrences(value)\n",
    "    \n",
    "    \n",
    "    \n",
    "key_list = []\n",
    "\n",
    "for key in hashtags_dict_counted.keys():\n",
    "    key_list.append(key)\n",
    "    \n",
    "key_list = sorted(key_list)\n",
    "\n",
    "\n",
    "\n",
    "hashtag_list = []\n",
    "\n",
    "for element in key_list:\n",
    "    hashtags_dict_sorted = sorted(hashtags_dict_counted[element].items(), key=operator.itemgetter(1), reverse=True)\n",
    "    if len(hashtags_dict_sorted) > 2:\n",
    "        for x in range(0, 2):\n",
    "            hashtag_list.append(hashtags_dict_sorted[x][0])\n",
    "    else:\n",
    "        for x in range(0, len(hashtags_dict_sorted)):\n",
    "            hashtag_list.append(hashtags_dict_sorted[x][0])\n",
    "        \n",
    "        \n",
    "hashtag_set = sorted(set(hashtag_list))\n",
    "\n",
    "\n",
    "\n",
    "hashtag_df = pd.DataFrame({\"Dates\":key_list})\n",
    "\n",
    "\n",
    "for hashtag in hashtag_set:\n",
    "    hashtag_value_list = []\n",
    "    for element in key_list:\n",
    "        try:\n",
    "            hashtag_value_list.append(hashtags_dict_counted[element][hashtag])\n",
    "        except KeyError:\n",
    "            hashtag_value_list.append(0)\n",
    "    hashtag_df[hashtag] = pd.Series(hashtag_value_list, index=hashtag_df.index)\n",
    "    \n",
    "    \n",
    "#hashtag_df.to_csv(r'ib_hashtag_df.txt', header=True, index=None, sep='|', mode='w', encoding=\"utf-8\")\n",
    "\n",
    "hashtag_df_index = hashtag_df.set_index([\"Dates\"]).sort_index()\n",
    "\n",
    "#hashtag_df.to_csv(r'boehmermann_hashtag_df.txt', header=True, index=None, sep='|', mode='w', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Gruppe 3: 'Taz - Die Tageszeitung'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~vwestric/131.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = go.Layout(\n",
    "    title='Am häufigsten verwendete Hashtags'\n",
    ")\n",
    "\n",
    "hashtag_df.iplot(x='Dates',kind='scatter', layout = layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~vwestric/133.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = []\n",
    "temp_values = []\n",
    "values = []\n",
    "\n",
    "phrase_dict = {}\n",
    "\n",
    "\n",
    "with open(\"bar_charts/taz_chemnitz_tweets_phrase_count.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line_stripped = line.strip(\"\\n\")\n",
    "        line_splitted = line_stripped.split(\"|\")\n",
    "        temp_values.append(int(line_splitted[1]))\n",
    "        phrase_dict[line_splitted[0]] = int(line_splitted[1])\n",
    "        \n",
    "#((sum(temp_values)/len(temp_values)) * 2)      \n",
    "        \n",
    "for key, value in phrase_dict.items():\n",
    "    if value > ((sum(temp_values)/len(temp_values)) * 2):\n",
    "        phrases.append(key)\n",
    "        values.append(value)\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Am häufigsten verwendete Adjektiv-Subjektiv-Kombinationen in #Chemnitz-Tweets'\n",
    ")        \n",
    "        \n",
    "data = [go.Bar(\n",
    "            x=phrases,\n",
    "            y=values\n",
    "    )]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~vwestric/135.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = []\n",
    "temp_values = []\n",
    "values = []\n",
    "\n",
    "phrase_dict = {}\n",
    "\n",
    "\n",
    "with open(\"bar_charts/taz_chemnitz_tweets_word_count.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line_stripped = line.strip(\"\\n\")\n",
    "        line_splitted = line_stripped.split(\"|\")\n",
    "        temp_values.append(int(line_splitted[1]))\n",
    "        phrase_dict[line_splitted[0]] = int(line_splitted[1])\n",
    "        \n",
    "#((sum(temp_values)/len(temp_values)) * 2)      \n",
    "        \n",
    "for key, value in phrase_dict.items():\n",
    "    if value > ((sum(temp_values)/len(temp_values)) * 2):\n",
    "        phrases.append(key)\n",
    "        values.append(value)\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Am häufigsten verwendete Wörter in #Chemnitz-Tweets'\n",
    ")        \n",
    "        \n",
    "data = [go.Bar(\n",
    "            x=phrases,\n",
    "            y=values\n",
    "    )]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_dates = []\n",
    "hashtags_dict = {}\n",
    "\n",
    "with open(\"projektdaten/spon_1000_hashtags_dated.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    file_name = str(file).strip(\"projektdaten/\")\n",
    "    file_name = file_name.strip(\"_hashtags_dated.txt\")\n",
    "    for line in file:\n",
    "        line_stripped = line.strip(\"\\ufeff\")\n",
    "        line_stripped = line_stripped.strip(\"\\n\")\n",
    "        line_splitted = line_stripped.split(\"|\")\n",
    "        line_1_stripped = line_splitted[1].strip(\"\\'\")\n",
    "        line_1_stripped = line_1_stripped.strip(\" \")\n",
    "        line_1_stripped = line_1_stripped.strip(\"[\")\n",
    "        line_1_stripped = line_1_stripped.strip(\"]\")\n",
    "        hashtags = line_1_stripped.split(\",\")\n",
    "\n",
    "        if line_splitted[0] not in hashtags_dict.keys():\n",
    "            hashtags_dict[line_splitted[0]] = hashtags\n",
    "        else:\n",
    "            hashtags_dict[line_splitted[0]].extend(hashtags)\n",
    "\n",
    "def removekey(d, key):\n",
    "    r = dict(d)\n",
    "    del r[key]\n",
    "    return r\n",
    "\n",
    "datelist = pd.date_range(pd.datetime.today()- timedelta(days=30), periods=30).tolist()\n",
    "datestrings = []\n",
    "for element in datelist:\n",
    "    datestrings.append(str(element.date()))\n",
    "\n",
    "\n",
    "hashtags_dict_new = {}\n",
    "\n",
    "for element in datestrings:\n",
    "    try:\n",
    "        hashtags_dict_new[element] = hashtags_dict[element]\n",
    "    except KeyError:\n",
    "        continue\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "hashtags_dict_counted = {}\n",
    "hashtags_dict_sorted = {}\n",
    "\n",
    "for key, value in hashtags_dict_new.items():\n",
    "    hashtags_dict_counted[key] = useful.count_occurrences(value)\n",
    "    \n",
    "    \n",
    "    \n",
    "key_list = []\n",
    "\n",
    "for key in hashtags_dict_counted.keys():\n",
    "    key_list.append(key)\n",
    "    \n",
    "key_list = sorted(key_list)\n",
    "\n",
    "\n",
    "\n",
    "hashtag_list = []\n",
    "\n",
    "for element in key_list:\n",
    "    hashtags_dict_sorted = sorted(hashtags_dict_counted[element].items(), key=operator.itemgetter(1), reverse=True)\n",
    "    if len(hashtags_dict_sorted) > 2:\n",
    "        for x in range(0, 2):\n",
    "            hashtag_list.append(hashtags_dict_sorted[x][0])\n",
    "    else:\n",
    "        for x in range(0, len(hashtags_dict_sorted)):\n",
    "            hashtag_list.append(hashtags_dict_sorted[x][0])\n",
    "        \n",
    "        \n",
    "hashtag_set = sorted(set(hashtag_list))\n",
    "\n",
    "\n",
    "\n",
    "hashtag_df = pd.DataFrame({\"Dates\":key_list})\n",
    "\n",
    "\n",
    "for hashtag in hashtag_set:\n",
    "    hashtag_value_list = []\n",
    "    for element in key_list:\n",
    "        try:\n",
    "            hashtag_value_list.append(hashtags_dict_counted[element][hashtag])\n",
    "        except KeyError:\n",
    "            hashtag_value_list.append(0)\n",
    "    hashtag_df[hashtag] = pd.Series(hashtag_value_list, index=hashtag_df.index)\n",
    "    \n",
    "    \n",
    "#hashtag_df.to_csv(r'ib_hashtag_df.txt', header=True, index=None, sep='|', mode='w', encoding=\"utf-8\")\n",
    "\n",
    "hashtag_df_index = hashtag_df.set_index([\"Dates\"]).sort_index()\n",
    "\n",
    "#hashtag_df.to_csv(r'boehmermann_hashtag_df.txt', header=True, index=None, sep='|', mode='w', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Gruppe 4: 'Spiegel Online'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~vwestric/137.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = go.Layout(\n",
    "    title='Am häufigsten verwendete Hashtags'\n",
    ")\n",
    "\n",
    "hashtag_df.iplot(x='Dates',kind='scatter', layout = layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~vwestric/139.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = []\n",
    "temp_values = []\n",
    "values = []\n",
    "\n",
    "phrase_dict = {}\n",
    "\n",
    "\n",
    "with open(\"bar_charts/spon_chemnitz_tweets_phrase_count.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line_stripped = line.strip(\"\\n\")\n",
    "        line_splitted = line_stripped.split(\"|\")\n",
    "        temp_values.append(int(line_splitted[1]))\n",
    "        phrase_dict[line_splitted[0]] = int(line_splitted[1])\n",
    "        \n",
    "#((sum(temp_values)/len(temp_values)) * 2)      \n",
    "        \n",
    "for key, value in phrase_dict.items():\n",
    "    if value > ((sum(temp_values)/len(temp_values)) * 2):\n",
    "        phrases.append(key)\n",
    "        values.append(value)\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Am häufigsten verwendete Adjektiv-Subjektiv-Kombinationen in #Chemnitz-Tweets'\n",
    ")        \n",
    "        \n",
    "data = [go.Bar(\n",
    "            x=phrases,\n",
    "            y=values\n",
    "    )]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~vwestric/141.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = []\n",
    "temp_values = []\n",
    "values = []\n",
    "\n",
    "phrase_dict = {}\n",
    "\n",
    "\n",
    "with open(\"bar_charts/spon_chemnitz_tweets_word_count.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line_stripped = line.strip(\"\\n\")\n",
    "        line_splitted = line_stripped.split(\"|\")\n",
    "        temp_values.append(int(line_splitted[1]))\n",
    "        phrase_dict[line_splitted[0]] = int(line_splitted[1])\n",
    "        \n",
    "#((sum(temp_values)/len(temp_values)) * 2)      \n",
    "        \n",
    "for key, value in phrase_dict.items():\n",
    "    if value > ((sum(temp_values)/len(temp_values)) * 2):\n",
    "        phrases.append(key)\n",
    "        values.append(value)\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Am häufigsten verwendete Wörter in #Chemnitz-Tweets'\n",
    ")        \n",
    "        \n",
    "data = [go.Bar(\n",
    "            x=phrases,\n",
    "            y=values\n",
    "    )]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Fazit \n",
    "\n",
    "Die Visualisierung funktioniert erwartungsgemäß. Um die Darstellung analyiseren zu können muss die Fragestellung genauer definiert und theorethisch unterfüttert werden. 'Chemnitz' als Hashtag ist allerdings in allen vier Gruppen außerordentlich prominent vertreten."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
